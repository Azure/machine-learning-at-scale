# PyTorch Distributed Data Parallel (DDP)

This example shows how to use Distributed Data Parallel (DDP) with PyTorch on Azure Machine Learning.


## Prerequisites
- Azure Machine Learning Workspace
    - Compute Clusters with GPU for distributed training
    - Compute Instance with Azure ML CLI 2.0 installed

## Reference
- [PyTorch Distributed Data Parallel (DDP)][1]
[1]: https://pytorch.org/docs/stable/distributed.html
